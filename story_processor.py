import json
import os
import time
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# -------------------------------------------------------------------------
# [ì„¤ì •] Azure OpenAI API ì •ë³´
# -------------------------------------------------------------------------
client = AzureOpenAI(
    api_key=os.getenv("AZURE_API_KEY"),  
    api_version=os.getenv("AZURE_API_VERSION"), 
    azure_endpoint=os.getenv("AZURE_ENDPOINT")
)

# -------------------------------------------------------------------------
# [í•¨ìˆ˜ 1] GPT-5 ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ (í”„ë¡¬í”„íŠ¸ ëŒ€í­ ìˆ˜ì •)
# -------------------------------------------------------------------------
def analyze_story_with_gpt(story_data):
    sorted_keys = sorted(story_data['pages'].keys(), key=int)
    full_text = " ".join([story_data['pages'][k] for k in sorted_keys])
    title = story_data['title']

    print(f"â–¶ï¸ [ë¶„ì„ ì‹œì‘] '{title}' (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_text)}ì)")

    # â˜… í•µì‹¬ ìˆ˜ì •: í™”ì ì œí•œ ë° í•´ì„¤ í™•ì¥ ì§€ì‹œ ê°•í™”
    system_prompt = """
    ë‹¹ì‹ ì€ ì–´ë¦°ì´ ìœ íŠœë¸Œ ì±„ë„ì„ ìœ„í•œ 'ì „ë˜ë™í™” ì‹œë‚˜ë¦¬ì˜¤ ì „ë¬¸ ê°ìƒ‰ê°€'ì…ë‹ˆë‹¤.
    ì œê³µëœ ë™í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜ìƒ ì œì‘ìš© JSON ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.

    [í™”ì(Role) ì„ íƒ ê·œì¹™ - ì—„ê²© ì¤€ìˆ˜]
    ëŒ€ì‚¬ì˜ í™”ì(role)ëŠ” ë°˜ë“œì‹œ ì•„ë˜ ëª©ë¡ ì¤‘ì—ì„œë§Œ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ëª©ë¡ì— ì—†ëŠ” ë‹¨ì–´(ì˜ˆ: ì—„ë§ˆ, í–‰ì¸, í˜¸ë‘ì´)ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    - í—ˆìš© ëª©ë¡: [í•´ì„¤, ë‚¨ìì•„ì´, ì—¬ìì•„ì´, ì†Œë…„, ì†Œë…€, ì²­ë…„, ì²˜ë…€, í• ì•„ë²„ì§€, í• ë¨¸ë‹ˆ, ì•…ë‹¹, ë™ë¬¼, ì‹ /ìš”ì •]
    
    [ì‹œë‚˜ë¦¬ì˜¤ ì‘ì„± ì§€ì¹¨]
    1. **ì¥ë©´ êµ¬ì„±**: ì „ì²´ ì´ì•¼ê¸°ë¥¼ **6~10ê°œì˜ í•µì‹¬ ì¥ë©´(Scene)**ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”.
    2. **ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸(visual_prompt)**: í•œêµ­ì–´ë¡œ êµ¬ì²´ì ì´ê³  ì„œì •ì ì¸ ë¬˜ì‚¬ (ì˜ˆ: ë”°ëœ»í•œ ìˆ˜ì±„í™”í’, ì§€ë¸Œë¦¬ ìŠ¤íƒ€ì¼ ë“±).
    3. **í•´ì„¤(í•´ì„¤ role)ì˜ í™•ì¥**: ì›ë¬¸ì˜ ë‹¨ìˆœí•œ ì„œìˆ ì„ **êµ¬ì—°ë™í™”ì— ë§ê²Œ ëŒ€í­ ëŠ˜ë ¤ì„œ ê°ìƒ‰**í•˜ì„¸ìš”. 
       - ìƒí™© ë¬˜ì‚¬, ë“±ì¥ì¸ë¬¼ì˜ ê°ì •, ë°°ê²½ ë¶„ìœ„ê¸° ë“±ì„ í’ë¶€í•˜ê²Œ ë§ë¶™ì—¬ ë¬¸ì¥ì„ ê¸¸ê³  ë§›ê¹”ë‚˜ê²Œ ë§Œë“œì„¸ìš”.
       - ì˜ˆ: "í¥ë¶€ê°€ ì«“ê²¨ë‚¬ë‹¤" (X) -> "ìš•ì‹¬ìŸì´ í˜• ë†€ë¶€ì—ê²Œ ë§¤ëª°ì°¨ê²Œ ì«“ê²¨ë‚œ í¥ë¶€ëŠ”, ìŒ€ í•œ í†¨ ì—†ì´ ë¹ˆì†ìœ¼ë¡œ í„°ëœí„°ëœ ì§‘ì„ ë‚˜ì„¤ ìˆ˜ë°–ì— ì—†ì—ˆë‹µë‹ˆë‹¤. ì°¬ë°”ëŒì´ ìŒ©ìŒ© ë¶€ëŠ” ê°€ì„ë‚ ì´ì—ˆì§€ìš”." (O)
    4. **ìºë¦­í„° ëŒ€ì‚¬**: ë“±ì¥ì¸ë¬¼ì˜ ëŒ€ì‚¬ëŠ” ì›ë¬¸ì˜ ë§›ì„ ì‚´ë¦¬ë˜ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ì–´ì£¼ì„¸ìš”.
    5. **JSON í¬ë§· ì—„ìˆ˜**: ì˜¤ì§ JSON ê°ì²´ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

    [JSON ì˜ˆì‹œ]
    {
      "title": "í¥ë¶€ì „",
      "scenes": [
        {
          "scene_num": 1,
          "visual_prompt": "ê°€ì„ë°”ëŒì´ ë¶€ëŠ” ë†€ë¶€ë„¤ ê¸°ì™€ì§‘ ëŒ€ë¬¸ ì•, ì«“ê²¨ë‚˜ëŠ” í¥ë¶€ ê°€ì¡±ì˜ ë’·ëª¨ìŠµ. ì“¸ì“¸í•˜ê³  ìŠ¬í”ˆ ë¶„ìœ„ê¸°. ìˆ˜ì±„í™”í’.",
          "scripts": [
            {"role": "í•´ì„¤", "text": "ì˜›ë‚  ì–´ëŠ ë§ˆì„ì— ìš•ì‹¬ ë§ì€ í˜• ë†€ë¶€ì™€ ë§ˆìŒì”¨ ì°©í•œ ë™ìƒ í¥ë¶€ê°€ ì‚´ê³  ìˆì—ˆì–´ìš”. ì–´ëŠ ì¶”ìš´ ê²¨ìš¸ë‚ , ë†€ë¶€ëŠ” ë¶€ëª¨ë‹˜ì´ ë¬¼ë ¤ì£¼ì‹  ì¬ì‚°ì„ í˜¼ì ëª½ë•… ì°¨ì§€í•˜ê³ ëŠ” ê°€ì—¬ìš´ í¥ë¶€ ê°€ì¡±ì„ ë¹ˆì†ìœ¼ë¡œ ë‚´ì«“ì•„ ë²„ë ¸ë‹µë‹ˆë‹¤."},
            {"role": "ì•…ë‹¹", "text": "ì© êº¼ì§€ê±°ë¼! ë‚´ ëˆˆì•ì— ë‹¤ì‹œëŠ” ë„ì§€ ë§ˆ!"},
            {"role": "ì†Œë…„", "text": "í˜•ë‹˜, ì œë°œ ì €í¬ ì•„ì´ë“¤ì„ ë´ì„œë¼ë„ ì¡°ê¸ˆë§Œ ë„ì™€ì£¼ì„¸ìš”."}
          ]
        }
      ]
    }
    """

    try:
        response = client.chat.completions.create(
            model=os.getenv("AZURE_DEPLOYMENT_NAME"), 
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ë™í™” ë‚´ìš©:\n{full_text}"}
            ],
            response_format={"type": "json_object"},
            temperature=0.7 # ì°½ì˜ì ì¸ ê°ìƒ‰ì„ ìœ„í•´ ì˜¨ë„ë¥¼ ì•½ê°„ ë†’ê²Œ ìœ ì§€
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ ({title}): {e}")
        return None

# -------------------------------------------------------------------------
# [í•¨ìˆ˜ 2] ë©”ì¸ ì‹¤í–‰
# -------------------------------------------------------------------------
def process_crawled_data(input_file, output_file, limit=None):
    if not os.path.exists(input_file):
        print("âŒ í¬ë¡¤ë§ ëœ json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(input_file, 'r', encoding='utf-8') as f:
        crawled_data = json.load(f) 

    # ë”•ì…”ë„ˆë¦¬ ì•„ì´í…œì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    all_items = list(crawled_data.items())
    total_count = len(all_items)
    
    # limit ì ìš©
    if limit is not None:
        target_items = all_items[:limit]
        print(f"ğŸ“š í¬ë¡¤ë§ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {total_count}ê°œ ì¤‘ {limit}ê°œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n")
    else:
        target_items = all_items
        print(f"ğŸ“š í¬ë¡¤ë§ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {total_count}ê°œ ì „ì²´ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n")
    
    final_results = []

    # ìˆœíšŒ ë° ì²˜ë¦¬
    for index, (seq_id, story_content) in enumerate(target_items):
        print(f"[{index+1}/{len(target_items)}] ì²˜ë¦¬ ì¤‘...")
        
        analyzed = analyze_story_with_gpt(story_content)
        
        if analyzed:
            analyzed['original_seq'] = seq_id 
            final_results.append(analyzed)
            print(f"âœ… '{analyzed['title']}' ì²˜ë¦¬ ì™„ë£Œ!\n")
        
        time.sleep(1) 

    # ê²°ê³¼ ì €ì¥
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_results, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ‰ ì‘ì—… ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {output_file}")

# --- ì‹¤í–‰ ---
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 2ê°œë§Œ ì‹¤í–‰
    process_crawled_data("fairy_tales.json", "processed_stories.json", limit=2)