import json
import os
import time
import azure.cognitiveservices.speech as speechsdk
from dotenv import load_dotenv

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

SPEECH_KEY = os.getenv("SPEECH_KEY")
SPEECH_REGION = os.getenv("SPEECH_REGION")

# -------------------------------------------------------------------------
# [ì„¤ì •] í™”ì(Role) <-> Azure AI Speech ë³´ì´ìŠ¤ ë§¤í•‘ (ì´ë¯¸ì§€ ê¸°ë°˜ ìµœì í™”)
# -------------------------------------------------------------------------
VOICE_MAPPING = {
    # 1. í•´ì„¤ (Narrator): ì§€ì‹ ì „ë‹¬ì— ëŠ¥í•œ í˜„ìˆ˜ ë©€í‹°ë§êµ¬ì–¼
    "í•´ì„¤": "ko-KR-HyunsuMultilingualNeural",
    
    # 2. ì•„ë™ ìºë¦­í„° (Kids)
    # ì„œí˜„(SeoHyeon)ì€ ì‹¤ì œ ì–´ë¦°ì´ ëª©ì†Œë¦¬ë¼ ì†Œë…€ ì—­í• ì— ì™„ë²½í•©ë‹ˆë‹¤.
    "ì—¬ìì•„ì´": "ko-KR-SeoHyeonNeural",
    "ì†Œë…€": "ko-KR-SeoHyeonNeural",
    
    # ì¸ì¤€(InJoon)ì€ ì¹œê·¼í•œ í†¤ì´ë¼ ì†Œë…„ ì—­í• ë¡œ ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.
    "ë‚¨ìì•„ì´": "ko-KR-InJoonNeural", 
    "ì†Œë…„": "ko-KR-InJoonNeural",
    
    # 3. ì„±ì¸ ì—¬ì„± (Adult Female)
    # ìœ ì§„(YuJin)ì€ ë°ê³  ì Šì€ í†¤ (ì£¼ì¸ê³µ ì²˜ë…€)
    "ì²˜ë…€": "ko-KR-YuJinNeural",
    
    # ì§€ë¯¼(JiMin)ì€ ë¶€ë“œëŸ¬ìš´ í†¤ (ì°¨ë¶„í•œ ì–´ë¨¸ë‹ˆ/ì•„ì£¼ë¨¸ë‹ˆ)
    "ì•„ì£¼ë¨¸ë‹ˆ": "ko-KR-JiMinNeural",
    
    # 4. ì„±ì¸ ë‚¨ì„± (Adult Male)
    # êµ­ë¯¼(GookMin)ì„ ì²­ë…„ ì—­í• ë¡œ ë°°ì •í•˜ì—¬ ë‹¤ì–‘ì„± í™•ë³´
    "ì²­ë…„": "ko-KR-GookMinNeural",
    
    # 5. ë…¸ì¸ ë° íŠ¹ìˆ˜ ë°°ì—­ (Elderly & Special)
    # ìˆœë³µ(SoonBok)ì€ ìƒë™ê°(Animated)ì´ ìˆì–´ í• ë¨¸ë‹ˆ ì—°ê¸°ì— ì í•©
    "í• ë¨¸ë‹ˆ": "ko-KR-SoonBokNeural",
    
    # ë´‰ì§„(BongJin)ì€ ëª©ì†Œë¦¬ê°€ êµµê³  ì¤‘í›„í•˜ì—¬ í• ì•„ë²„ì§€ë‚˜ ì•…ë‹¹ì— ì œê²©
    "í• ì•„ë²„ì§€": "ko-KR-BongJinNeural",
    "ì•…ë‹¹": "ko-KR-BongJinNeural",
    
    # ì„ í¬(SunHi)ëŠ” ì°¨ë¶„í•˜ê³  ìœ„ë¡œê°€ ë˜ëŠ”(Soothing) í†¤ì´ë¼ ì‹ ìš”ì • ì—­í• 
    "ì‹ ìš”ì •": "ko-KR-SunHiNeural", # (Dragon HD í€„ë¦¬í‹° ëŒ€ì‘)
    "ë™ë¬¼": "ko-KR-InJoonNeural"    # ë™ë¬¼ì€ í¸ì•ˆí•œ í†¤ìœ¼ë¡œ ì„¤ì • (í•„ìš” ì‹œ í”¼ì¹˜ ì¡°ì ˆ)
}

DEFAULT_VOICE = "ko-KR-SunHiNeural" # ê¸°ë³¸ê°’

# -------------------------------------------------------------------------
# [í•¨ìˆ˜] TTS ìƒì„± ë° íŒŒì¼ ì €ì¥ (Azure Speech SDK ì‚¬ìš©)
# -------------------------------------------------------------------------
def generate_tts_for_story(story_data, output_base_dir="output_assets"):
    title = story_data['title']
    safe_title = "".join([c for c in title if c.isalnum() or c in (' ', '_')]).strip()
    
    save_dir = os.path.join(output_base_dir, safe_title, "audio")
    os.makedirs(save_dir, exist_ok=True)
    
    print(f"ğŸ™ï¸ [TTS ì‹œì‘] '{title}' ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...")
    
    if not SPEECH_KEY or not SPEECH_REGION:
        print("âŒ ì˜¤ë¥˜: .env íŒŒì¼ì— SPEECH_KEY ë˜ëŠ” SPEECH_REGIONì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    
    scenes = story_data.get('scenes', [])
    total_scripts = sum(len(scene['scripts']) for scene in scenes)
    current_count = 0

    for scene in scenes:
        scene_num = scene['scene_num']
        
        for idx, script in enumerate(scene['scripts']):
            role = script['role']
            text = script['text']
            
            # 1. ë³´ì´ìŠ¤ ì„ íƒ
            voice_name = VOICE_MAPPING.get(role, DEFAULT_VOICE)
            
            # 2. íŒŒì¼ëª… ê·œì¹™
            filename = f"S{scene_num:02d}_{idx:03d}_{role}_{voice_name}.mp3"
            filepath = os.path.join(save_dir, filename)
            
            if os.path.exists(filepath):
                current_count += 1
                continue

            try:
                # 3. Azure Speech SDK ì„¤ì •
                speech_config.speech_synthesis_voice_name = voice_name
                audio_config = speechsdk.audio.AudioOutputConfig(filename=filepath)
                
                # í•©ì„±ê¸° ìƒì„±
                synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
                
                # 4. í•©ì„± ì‹¤í–‰
                result = synthesizer.speak_text_async(text).get()

                if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                    current_count += 1
                    print(f"  âœ… [{current_count}/{total_scripts}] {filename} ({role})")
                elif result.reason == speechsdk.ResultReason.Canceled:
                    details = result.cancellation_details
                    print(f"  âŒ ì·¨ì†Œë¨: {filename} - {details.reason}")
                    if details.reason == speechsdk.CancellationReason.Error:
                        print(f"     ì—ëŸ¬ ìƒì„¸: {details.error_details}")

            except Exception as e:
                print(f"  âŒ ì˜ˆì™¸ ë°œìƒ: {filename} - {e}")
                time.sleep(1)

    print(f"ğŸ‰ '{title}' ì˜¤ë””ì˜¤ ìƒì„± ì™„ë£Œ! ìœ„ì¹˜: {save_dir}\n")

# -------------------------------------------------------------------------
# [ë©”ì¸] ì‹¤í–‰ ë¡œì§
# -------------------------------------------------------------------------
def main(input_json_file):
    if not os.path.exists(input_json_file):
        print("âŒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    with open(input_json_file, 'r', encoding='utf-8') as f:
        stories = json.load(f)

    print(f"ğŸ“š ì´ {len(stories)}í¸ì˜ ë™í™” ì˜¤ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    print(f"âœ¨ ì ìš©ëœ ì£¼ìš” ì„±ìš°: ì„œí˜„(ì•„ì—­), ìˆœë³µ(í• ë¨¸ë‹ˆ), í˜„ìˆ˜ë©€í‹°(í•´ì„¤), ë´‰ì§„(ì•…ë‹¹) ë“±")

    for story in stories:
        generate_tts_for_story(story)

if __name__ == "__main__":
    INPUT_FILE = "processed_stories.json"
    main(INPUT_FILE)